{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cbd3357-d5b6-4f01-ad02-21c59301ce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204831, 25)\n",
      "Index(['Unnamed: 0', 'noun', 'comments', 'rated_indiv', 'date_post',\n",
      "       'reviewer', 'number_of_reveiws', 'loc_reviewer', 'restaurant_name',\n",
      "       'review_translated', 'review_full', 'tokenized_text', 'adjectives',\n",
      "       'value', 'Sentiment_adj1_pos', 'Sentiment_adj1_neutral',\n",
      "       'Sentiment_adj1_neg', 'Bigram', 'Sentiment_bigram_pos',\n",
      "       'Sentiment_bigram_neutral', 'Sentiment_bigram_neg',\n",
      "       'Sentiment_text_pos', 'Sentiment_text_neutral', 'Sentiment_text_neg',\n",
      "       'noun_grouped'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>noun</th>\n",
       "      <th>comments</th>\n",
       "      <th>rated_indiv</th>\n",
       "      <th>date_post</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>number_of_reveiws</th>\n",
       "      <th>loc_reviewer</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>review_translated</th>\n",
       "      <th>...</th>\n",
       "      <th>Sentiment_adj1_neutral</th>\n",
       "      <th>Sentiment_adj1_neg</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Sentiment_bigram_pos</th>\n",
       "      <th>Sentiment_bigram_neutral</th>\n",
       "      <th>Sentiment_bigram_neg</th>\n",
       "      <th>Sentiment_text_pos</th>\n",
       "      <th>Sentiment_text_neutral</th>\n",
       "      <th>Sentiment_text_neg</th>\n",
       "      <th>noun_grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Mi stupisco come alcuni abbiamo dato 5* a ques...</td>\n",
       "      <td>10</td>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>['enstrop']</td>\n",
       "      <td>['5 reviews']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lavash</td>\n",
       "      <td>I am amazed how some have given 5* to this res...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA *</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>restaurant</td>\n",
       "      <td>Mi stupisco come alcuni abbiamo dato 5* a ques...</td>\n",
       "      <td>10</td>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>['enstrop']</td>\n",
       "      <td>['5 reviews']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lavash</td>\n",
       "      <td>I am amazed how some have given 5* to this res...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA restaurant</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>food</td>\n",
       "      <td>Mi stupisco come alcuni abbiamo dato 5* a ques...</td>\n",
       "      <td>10</td>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>['enstrop']</td>\n",
       "      <td>['5 reviews']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lavash</td>\n",
       "      <td>I am amazed how some have given 5* to this res...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NA food</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>food</td>\n",
       "      <td>We were there twice, incredibly good tasty foo...</td>\n",
       "      <td>50</td>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>['Knud K']</td>\n",
       "      <td>['2 reviews']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lavash</td>\n",
       "      <td>We were there twice, incredibly good tasty foo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good food</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>price</td>\n",
       "      <td>We were there twice, incredibly good tasty foo...</td>\n",
       "      <td>50</td>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>['Knud K']</td>\n",
       "      <td>['2 reviews']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Lavash</td>\n",
       "      <td>We were there twice, incredibly good tasty foo...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reasonable price</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "      <td>price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        noun                                           comments  \\\n",
       "0           0           *  Mi stupisco come alcuni abbiamo dato 5* a ques...   \n",
       "1           1  restaurant  Mi stupisco come alcuni abbiamo dato 5* a ques...   \n",
       "2           2        food  Mi stupisco come alcuni abbiamo dato 5* a ques...   \n",
       "3           3        food  We were there twice, incredibly good tasty foo...   \n",
       "4           4       price  We were there twice, incredibly good tasty foo...   \n",
       "\n",
       "   rated_indiv          date_post     reviewer number_of_reveiws loc_reviewer  \\\n",
       "0           10  February 12, 2023  ['enstrop']     ['5 reviews']           []   \n",
       "1           10  February 12, 2023  ['enstrop']     ['5 reviews']           []   \n",
       "2           10  February 12, 2023  ['enstrop']     ['5 reviews']           []   \n",
       "3           50   February 9, 2023   ['Knud K']     ['2 reviews']           []   \n",
       "4           50   February 9, 2023   ['Knud K']     ['2 reviews']           []   \n",
       "\n",
       "  restaurant_name                                  review_translated  ...  \\\n",
       "0          Lavash  I am amazed how some have given 5* to this res...  ...   \n",
       "1          Lavash  I am amazed how some have given 5* to this res...  ...   \n",
       "2          Lavash  I am amazed how some have given 5* to this res...  ...   \n",
       "3          Lavash  We were there twice, incredibly good tasty foo...  ...   \n",
       "4          Lavash  We were there twice, incredibly good tasty foo...  ...   \n",
       "\n",
       "  Sentiment_adj1_neutral Sentiment_adj1_neg            Bigram  \\\n",
       "0                    1.0                0.0              NA *   \n",
       "1                    1.0                0.0     NA restaurant   \n",
       "2                    1.0                0.0           NA food   \n",
       "3                    0.0                0.0         good food   \n",
       "4                    1.0                0.0  reasonable price   \n",
       "\n",
       "  Sentiment_bigram_pos  Sentiment_bigram_neutral  Sentiment_bigram_neg  \\\n",
       "0                0.000                     1.000                   0.0   \n",
       "1                0.000                     1.000                   0.0   \n",
       "2                0.000                     1.000                   0.0   \n",
       "3                0.744                     0.256                   0.0   \n",
       "4                0.000                     1.000                   0.0   \n",
       "\n",
       "   Sentiment_text_pos Sentiment_text_neutral  Sentiment_text_neg  noun_grouped  \n",
       "0               0.262                  0.738               0.000             *  \n",
       "1               0.262                  0.738               0.000          food  \n",
       "2               0.000                  0.639               0.361          food  \n",
       "3               0.262                  0.738               0.000          food  \n",
       "4               0.262                  0.738               0.000         price  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "data = glob('../data/*.csv')\n",
    "\n",
    "syrovarnya = pd.read_csv([x for x in data if 'syrovarnya' in x][0])\n",
    "print(syrovarnya.shape)\n",
    "print(syrovarnya.columns)\n",
    "syrovarnya.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbaf2b64-0725-4d3e-a9e7-5df9a71c7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-tone', num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone')\n",
    "\n",
    "nlp = pipeline(\"sentiment-analysis\", model=finbert, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a98590-7391-4fdb-8215-05ca9e1004d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf9c58d6-aaf4-40f2-aeab-469bb8326398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date_post',\n",
       " 'review_full',\n",
       " 'value',\n",
       " 'Sentiment_text_pos',\n",
       " 'Sentiment_text_neutral',\n",
       " 'Sentiment_text_neg']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_dev = ['date_post', 'review_full', 'value', 'Sentiment_text_pos', 'Sentiment_text_neutral', 'Sentiment_text_neg']\n",
    "columns_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a489d27-ebf4-4509-b991-93e165fc7e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_post</th>\n",
       "      <th>review_full</th>\n",
       "      <th>value</th>\n",
       "      <th>Sentiment_text_pos</th>\n",
       "      <th>Sentiment_text_neutral</th>\n",
       "      <th>Sentiment_text_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>i am amazed how some have given 5* to this res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>i am amazed how some have given 5* to this res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>we were there twice, incredibly good tasty foo...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>we were there twice, incredibly good tasty foo...</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>we were there twice, incredibly good tasty foo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           date_post                                        review_full  \\\n",
       "0  February 12, 2023  i am amazed how some have given 5* to this res...   \n",
       "2  February 12, 2023  i am amazed how some have given 5* to this res...   \n",
       "3   February 9, 2023  we were there twice, incredibly good tasty foo...   \n",
       "4   February 9, 2023  we were there twice, incredibly good tasty foo...   \n",
       "5   February 9, 2023  we were there twice, incredibly good tasty foo...   \n",
       "\n",
       "        value  Sentiment_text_pos  Sentiment_text_neutral  Sentiment_text_neg  \n",
       "0         NaN               0.262                   0.738               0.000  \n",
       "2         NaN               0.000                   0.639               0.361  \n",
       "3        good               0.262                   0.738               0.000  \n",
       "4  reasonable               0.262                   0.738               0.000  \n",
       "5         NaN               0.000                   1.000               0.000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = syrovarnya[columns_dev].copy()\n",
    "dev.drop_duplicates(inplace=True)\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b8f3398-9e8d-48cc-8cd7-af85586be043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_post</th>\n",
       "      <th>review_full</th>\n",
       "      <th>value</th>\n",
       "      <th>Sentiment_text_pos</th>\n",
       "      <th>Sentiment_text_neutral</th>\n",
       "      <th>Sentiment_text_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203799</th>\n",
       "      <td>September 13, 2016</td>\n",
       "      <td>delicious food, very friendly service and an e...</td>\n",
       "      <td>traditional</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203815</th>\n",
       "      <td>August 23, 2016</td>\n",
       "      <td>üëåüèºüëåüèºüëåüèº we really like to visit here ,,, very b...</td>\n",
       "      <td>tasty</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203835</th>\n",
       "      <td>July 30, 2016</td>\n",
       "      <td>great place with a good location: 5 minutes on...</td>\n",
       "      <td>smoking</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204219</th>\n",
       "      <td>March 1, 2019</td>\n",
       "      <td>excellent location, immediately in the heart o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204230</th>\n",
       "      <td>February 18, 2019</td>\n",
       "      <td>we've booked a table for two in non-smoking ar...</td>\n",
       "      <td>smoking</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204234</th>\n",
       "      <td>February 18, 2019</td>\n",
       "      <td>we've booked a table for two in non-smoking ar...</td>\n",
       "      <td>smoking</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204272</th>\n",
       "      <td>January 3, 2019</td>\n",
       "      <td>finally, in yerevan, i found that cute and tas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204313</th>\n",
       "      <td>November 4, 2018</td>\n",
       "      <td>dined here twice. german/viennese cuisine is v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204335</th>\n",
       "      <td>November 4, 2018</td>\n",
       "      <td>we lived in the ibis hotel (this is a neighbor...</td>\n",
       "      <td>great</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204504</th>\n",
       "      <td>November 9, 2022</td>\n",
       "      <td>love paul everywhere! and a particularly nice ...</td>\n",
       "      <td>unimaginable</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date_post                                        review_full  \\\n",
       "203799  September 13, 2016  delicious food, very friendly service and an e...   \n",
       "203815     August 23, 2016  üëåüèºüëåüèºüëåüèº we really like to visit here ,,, very b...   \n",
       "203835       July 30, 2016  great place with a good location: 5 minutes on...   \n",
       "204219       March 1, 2019  excellent location, immediately in the heart o...   \n",
       "204230   February 18, 2019  we've booked a table for two in non-smoking ar...   \n",
       "204234   February 18, 2019  we've booked a table for two in non-smoking ar...   \n",
       "204272     January 3, 2019  finally, in yerevan, i found that cute and tas...   \n",
       "204313    November 4, 2018  dined here twice. german/viennese cuisine is v...   \n",
       "204335    November 4, 2018  we lived in the ibis hotel (this is a neighbor...   \n",
       "204504    November 9, 2022  love paul everywhere! and a particularly nice ...   \n",
       "\n",
       "               value  Sentiment_text_pos  Sentiment_text_neutral  \\\n",
       "203799   traditional               0.108                   0.892   \n",
       "203815         tasty               0.489                   0.511   \n",
       "203835       smoking               0.000                   0.820   \n",
       "204219           NaN               0.592                   0.408   \n",
       "204230       smoking               0.000                   1.000   \n",
       "204234       smoking               0.085                   0.835   \n",
       "204272           NaN               0.158                   0.842   \n",
       "204313           NaN               0.444                   0.556   \n",
       "204335         great               0.626                   0.374   \n",
       "204504  unimaginable               0.442                   0.558   \n",
       "\n",
       "        Sentiment_text_neg  \n",
       "203799               0.000  \n",
       "203815               0.000  \n",
       "203835               0.180  \n",
       "204219               0.000  \n",
       "204230               0.000  \n",
       "204234               0.079  \n",
       "204272               0.000  \n",
       "204313               0.000  \n",
       "204335               0.000  \n",
       "204504               0.000  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bba0ef80-bb1a-438a-9ba9-8609ba4a79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(id_: int):\n",
    "    test = dev.loc[id_, 'review_full']\n",
    "    print(f'Sentence example for testing the correctness of the sentiment labels: --> \\n{test}')\n",
    "    res = nlp(test)[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "656d48dc-257a-4e56-b294-96495b54d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example for testing the correctness of the sentiment labels: --> \n",
      "i am amazed how some have given 5* to this restaurant. the food is really badly served; meat...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'Negative', 'score': 0.9985622763633728}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "abf16bb7-f218-4cc3-84c6-d752748c9028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example for testing the correctness of the sentiment labels: --> \n",
      "üëåüèºüëåüèºüëåüèº we really like to visit here ,,, very beautiful, calm, very tasty food and good serviceüëåüèºüëåüèºüëåüèºüëåüèº\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'Positive', 'score': 0.998593270778656}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(203815)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1815a11c-bbe2-4331-b57a-4439d175d095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example for testing the correctness of the sentiment labels: --> \n",
      "great place with a good location: 5 minutes on foot from republic square. very attentive staff, good italian food, desserts and coffee. you should visit at any time, whether for breakfast, coffee, lunch, dinner or cocktails. the only thing to be considered: there is no non-smoking area. strongly recommended!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'Positive', 'score': 0.9959787130355835}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(203835)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "845a2120-ef5d-4e03-9b62-c9d130633bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example for testing the correctness of the sentiment labels: --> \n",
      "dined here twice. german/viennese cuisine is very good. but the thai meat was a little overexposed. tiramisu - probably never eaten better! desserts were all without exception. service is pleasant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'Positive', 'score': 0.9999778270721436}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(204313)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0e0dd4-e987-409a-b02b-41234c012f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9d1741-ddbb-4217-893a-1acaac08fc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ae02085e-b22b-41ab-8eb4-d53cc03412a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example for testing the correctness of the sentiment labels: --> \n",
      "finally, in yerevan, i found that cute and tasty corner that i had been looking for for so long.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'Neutral', 'score': 0.9999741315841675}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(204272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5799fa2-c068-4871-ae79-0eca94c8a360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe1579-e66e-4fd7-9ff1-d111f4e17d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f85f6c5-8f48-40ce-9d03-54abcc827e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5952145f809d4db0b39cc8a3452b87ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIGABYTE\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\GIGABYTE\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1a29677852459da7e4abe81c3076ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)\"pytorch_model.bin\";:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b39e281d124769945cc65c0b408e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/256 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887b811b9da945f19f8f6e31867e7015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252f56eb5c294f73b8b2dbd6576954c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e382fb2e564fdbb591717c99387b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "nlp2 = pipeline(\"sentiment-analysis\",model=\"siebert/sentiment-roberta-large-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "566e7303-8df8-4526-a089-4653da4247cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(id_: int, nlp=nlp2):\n",
    "    test = dev.loc[id_, 'review_full']\n",
    "    print(f'Sentence example for testing the correctness of the sentiment labels: --> \\n{test}')\n",
    "    res = nlp(test)[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44616796-9d09-40be-bd19-f417aae2d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence example for testing the correctness of the sentiment labels: --> \n",
      "finally, in yerevan, i found that cute and tasty corner that i had been looking for for so long.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'label': 'POSITIVE', 'score': 0.9987906813621521}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(204272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c96c629-cba2-4afa-a292-c2e335d98620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28453a-72ad-4ff5-ab60-a69b2bb59879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca0a7a7c-745f-4fa4-b5d0-17298d9efb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976ef637e0cf4dbab59f3d7aaf8b59b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd79de0cc59b4ce6aeb9b79206a9240d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3430800a490447fb4679b10d331da7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)solve/main/vocab.txt:   0%|          | 0.00/234k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163536dacbb84c868aeb3e7eb0f6a9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)in/added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0423206d1304111a42a6e5e1f67d409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fa1f1ffbe043a69dd7ef0456044878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (‚Ä¶)\"pytorch_model.bin\";:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indolem/indobert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"indolem/indobert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d5bdf91-4fdc-4195-baf3-13215c0e0d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2777327299118042,\n",
       " 'start': 86,\n",
       " 'end': 124,\n",
       " 'answer': 'good italian food, desserts and coffee'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': \"what things/products the reviewer like about the restaraunts?\",\n",
    "    'context': \"\"\"great place with a good location: 5 minutes on foot from republic square. Nice staff, good italian food, desserts and coffee. you should visit at any time, whether for breakfast, coffee, lunch, dinner or cocktails. the only thing to be considered: there is no non-smoking area. \"\"\"\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9a4f6dc4-d95f-4b4c-83d5-86b90bf48a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "950f40c8-b8f4-4be5-8d62-5db5dcb18942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"deepset/deberta-v3-large-squad2\"\n",
    "\n",
    "# a) Get predictions\n",
    "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "QA_input = {\n",
    "    'question': 'Why is model conversion important?',\n",
    "    'context': 'The option to convert models between FARM and transformers gives freedom to the user and let people easily switch between frameworks.'\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "\n",
    "# b) Load model & tokenizer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c98e1b-5c31-44e2-8a57-3181cf781984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a15e4e86-3f82-456a-8679-a510e41ca270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_post</th>\n",
       "      <th>review_full</th>\n",
       "      <th>value</th>\n",
       "      <th>Sentiment_text_pos</th>\n",
       "      <th>Sentiment_text_neutral</th>\n",
       "      <th>Sentiment_text_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>i am amazed how some have given 5* to this res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February 12, 2023</td>\n",
       "      <td>i am amazed how some have given 5* to this res...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>we were there twice, incredibly good tasty foo...</td>\n",
       "      <td>good</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>we were there twice, incredibly good tasty foo...</td>\n",
       "      <td>reasonable</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>February 9, 2023</td>\n",
       "      <td>we were there twice, incredibly good tasty foo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204234</th>\n",
       "      <td>February 18, 2019</td>\n",
       "      <td>we've booked a table for two in non-smoking ar...</td>\n",
       "      <td>smoking</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204272</th>\n",
       "      <td>January 3, 2019</td>\n",
       "      <td>finally, in yerevan, i found that cute and tas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204313</th>\n",
       "      <td>November 4, 2018</td>\n",
       "      <td>dined here twice. german/viennese cuisine is v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204335</th>\n",
       "      <td>November 4, 2018</td>\n",
       "      <td>we lived in the ibis hotel (this is a neighbor...</td>\n",
       "      <td>great</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204504</th>\n",
       "      <td>November 9, 2022</td>\n",
       "      <td>love paul everywhere! and a particularly nice ...</td>\n",
       "      <td>unimaginable</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51819 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_post                                        review_full  \\\n",
       "0       February 12, 2023  i am amazed how some have given 5* to this res...   \n",
       "2       February 12, 2023  i am amazed how some have given 5* to this res...   \n",
       "3        February 9, 2023  we were there twice, incredibly good tasty foo...   \n",
       "4        February 9, 2023  we were there twice, incredibly good tasty foo...   \n",
       "5        February 9, 2023  we were there twice, incredibly good tasty foo...   \n",
       "...                   ...                                                ...   \n",
       "204234  February 18, 2019  we've booked a table for two in non-smoking ar...   \n",
       "204272    January 3, 2019  finally, in yerevan, i found that cute and tas...   \n",
       "204313   November 4, 2018  dined here twice. german/viennese cuisine is v...   \n",
       "204335   November 4, 2018  we lived in the ibis hotel (this is a neighbor...   \n",
       "204504   November 9, 2022  love paul everywhere! and a particularly nice ...   \n",
       "\n",
       "               value  Sentiment_text_pos  Sentiment_text_neutral  \\\n",
       "0                NaN               0.262                   0.738   \n",
       "2                NaN               0.000                   0.639   \n",
       "3               good               0.262                   0.738   \n",
       "4         reasonable               0.262                   0.738   \n",
       "5                NaN               0.000                   1.000   \n",
       "...              ...                 ...                     ...   \n",
       "204234       smoking               0.085                   0.835   \n",
       "204272           NaN               0.158                   0.842   \n",
       "204313           NaN               0.444                   0.556   \n",
       "204335         great               0.626                   0.374   \n",
       "204504  unimaginable               0.442                   0.558   \n",
       "\n",
       "        Sentiment_text_neg  \n",
       "0                    0.000  \n",
       "2                    0.361  \n",
       "3                    0.000  \n",
       "4                    0.000  \n",
       "5                    0.000  \n",
       "...                    ...  \n",
       "204234               0.079  \n",
       "204272               0.000  \n",
       "204313               0.000  \n",
       "204335               0.000  \n",
       "204504               0.000  \n",
       "\n",
       "[51819 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71089a0c-0e1d-4326-b284-90357135bb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7f158d8-6777-4485-89ed-036be0a18121",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 =  \"what are the reasons that the reviewer like the restaraunt?\"\n",
    "t2 =  \"what are the reasons that make the reviewer like the restaraunt?\"\n",
    "t3 =  \"why the user like this restaraunt (the reasons)?\"\n",
    "t4 =  \"what things/products the reviewer like about the restaraunts?\"\n",
    "t5 =  \"what things, products, anything the reviewer like about the restaraunts?\"\n",
    "templates = [t1, t2, t3, t4, t5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2cacf-656c-4583-a943-01c96d82841f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c564493d-7072-429d-95cf-2a1179ea3433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.04794149100780487,\n",
       " 'start': 79,\n",
       " 'end': 129,\n",
       " 'answer': 'nice staff, good italian food, desserts and coffee'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': t1,\n",
    "    'context': \"\"\"great place with a good location: 5 minutes on foot from republic square. \n",
    "    nice staff, good italian food, desserts and coffee. you should visit at any time, whether for breakfast, coffee, lunch, dinner or cocktails. \n",
    "    the only thing to be considered: there is no non-smoking area. \"\"\"\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9ad19-9aa2-4d50-a0e7-4a3af9bcacea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aaf9f-2800-4fed-bdd5-bee7184dcb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "31820e19-d95c-4814-8005-86c3ecb48a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.032154276967048645, 'start': 140, 'end': 148, 'answer': 'desserts'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_input = {\n",
    "    'question': t5,\n",
    "    'context': \"dined here twice. german/viennese cuisine is very good. but the thai meat was a little overexposed. tiramisu - probably never eaten better! desserts were all without exception. service is pleasant\"\n",
    "}\n",
    "res = nlp(QA_input)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052596aa-0f36-413e-8443-7fe1f0dfdccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ec45e-5d0b-4051-9b95-56f550dfc49e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6fb95f26-1a79-45de-9c8a-d909217b4077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'delicious food in a beautiful location! one of the best places to taste the real taste of khinkali! friendly and caring staff! what i want to emphasize is that the menu for children is free!'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ = dev.sample(3).review_full.tolist()\n",
    "list_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcccb20-718d-4cf5-9ca9-7441994376a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569377a2-73a0-4581-9a5b-49ab0095b836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f391176f-07b4-4600-a02e-22dd2c45e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.011675742454826832, 'start': 100, 'end': 125, 'answer': 'friendly and caring staff'}\n",
      "{'score': 0.014534522779285908, 'start': 100, 'end': 125, 'answer': 'friendly and caring staff'}\n",
      "{'score': 0.04703691229224205, 'start': 0, 'end': 38, 'answer': 'delicious food in a beautiful location'}\n",
      "{'score': 0.10712812095880508, 'start': 100, 'end': 125, 'answer': 'friendly and caring staff'}\n",
      "{'score': 0.04341522604227066, 'start': 0, 'end': 14, 'answer': 'delicious food'}\n"
     ]
    }
   ],
   "source": [
    "for t in templates:\n",
    "    QA_input = {\n",
    "        'question': t,\n",
    "        'context': list_[0]\n",
    "    }\n",
    "    res = nlp(QA_input)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb556d-6ef2-4105-8654-019c8d5f4635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685addfe-b101-4bf9-9728-b435d76d7b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a58257-22a7-4fa0-b3e3-4df63d53a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2d1ff6a7-b636-4ee3-b887-f59f0dc52159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.1494399607181549, 'start': 0, 'end': 39, 'answer': 'delicious food in a beautiful location!'}\n",
      "{'score': 0.05540307238698006, 'start': 99, 'end': 126, 'answer': ' friendly and caring staff!'}\n",
      "{'score': 0.12363703548908234, 'start': 0, 'end': 39, 'answer': 'delicious food in a beautiful location!'}\n",
      "{'score': 0.2659241855144501, 'start': 0, 'end': 39, 'answer': 'delicious food in a beautiful location!'}\n",
      "{'score': 0.2043609321117401, 'start': 0, 'end': 39, 'answer': 'delicious food in a beautiful location!'}\n"
     ]
    }
   ],
   "source": [
    "for t in templates:\n",
    "    QA_input = {\n",
    "        'question': t,\n",
    "        'context': list_[0]\n",
    "    }\n",
    "    res = nlp(QA_input)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ab758-77c9-49b9-9992-b8f3616b81ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa4fab-9756-47e5-b553-69ba1f815f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4eaa1-5e61-43dc-af0c-df2866595090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe47042-6ed6-4473-91d8-5ef0a63deb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14cf9b-b306-4e1f-abb5-f01d259fc6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036faa0b-db87-4883-ba8e-b83a03ed2350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74a54d-c2e8-4c13-a5f6-574aa6c8b057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e648b-1204-4203-8e9f-1d09d33a11cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead04ba-46cd-4ab5-8e1b-5c8bb585b409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31e3ce14-d55f-4873-953c-c1481edf85ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FARMReader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43mFARMReader\u001b[49m(model_name_or_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepset/roberta-base-squad2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# or \u001b[39;00m\n\u001b[0;32m      3\u001b[0m reader \u001b[38;5;241m=\u001b[39m TransformersReader(model_name_or_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepset/roberta-base-squad2\u001b[39m\u001b[38;5;124m\"\u001b[39m,tokenizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeepset/roberta-base-squad2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FARMReader' is not defined"
     ]
    }
   ],
   "source": [
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")\n",
    "# or \n",
    "reader = TransformersReader(model_name_or_path=\"deepset/roberta-base-squad2\",tokenizer=\"deepset/roberta-base-squad2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e146dcc8-98a4-4abe-8640-0f24705752b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc35eb-ed68-4e6c-91fc-7f11a823d2e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25da8155-399d-4480-b889-539f4e99f1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388f50b-67c6-4673-9606-7e01dbe16cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5724987-46bd-4b3a-a7cc-ebfaa1fb8b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2f851-4215-4d38-8e20-e2b99c6673a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97e5b6c8-740e-485b-9104-38e86f5ed758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea97e8aa-a48e-4d93-9f2d-31f45ebb68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: ['din', '##ed', 'here', 'twice', '.'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['here', 'twice', '.', 'german', '/'], Sentiment: positive, Score: 0.439\n",
      "Words: ['.', 'german', '/', 'vie', '##nne'], Sentiment: positive, Score: 0.439\n",
      "Words: ['/', 'vie', '##nne', '##se', 'cuisine'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['##nne', '##se', 'cuisine', 'is', 'very'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['cuisine', 'is', 'very', 'good', '.'], Sentiment: positive, Score: 0.439\n",
      "Words: ['very', 'good', '.', 'but', 'the'], Sentiment: positive, Score: 0.439\n",
      "Words: ['.', 'but', 'the', 'thai', 'meat'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['the', 'thai', 'meat', 'was', 'a'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['meat', 'was', 'a', 'little', 'over'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['a', 'little', 'over', '##ex', '##posed'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['over', '##ex', '##posed', '.', 'ti'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['##posed', '.', 'ti', '##ram', '##is'], Sentiment: positive, Score: 0.439\n",
      "Words: ['ti', '##ram', '##is', '##u', '-'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['##is', '##u', '-', 'probably', 'never'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['-', 'probably', 'never', 'eaten', 'better'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['never', 'eaten', 'better', '!', 'dessert'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['better', '!', 'dessert', '##s', 'were'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['dessert', '##s', 'were', 'all', 'without'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['were', 'all', 'without', 'exception', '.'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['without', 'exception', '.', 'service', 'is'], Sentiment: positive, Score: 0.439\n",
      "Words: ['.', 'service', 'is', 'pleasant'], Sentiment: neutral, Score: 0.439\n",
      "Words: ['is', 'pleasant'], Sentiment: neutral, Score: 0.439\n"
     ]
    }
   ],
   "source": [
    "text = \"dined here twice. german/viennese cuisine is very good. but the thai meat was a little overexposed. tiramisu - probably never eaten better! desserts were all without exception. service is pleasant\"\n",
    "\n",
    "tokens = tokenizer.tokenize(text)\n",
    "window_size = 5\n",
    "step_size = 2\n",
    "\n",
    "sentiment_probs = []\n",
    "for i in range(0, len(tokens), step_size):\n",
    "    window_tokens = tokens[i:i+window_size]\n",
    "    input_ids = torch.tensor([tokenizer.convert_tokens_to_ids(window_tokens)])\n",
    "    outputs = model(input_ids)[0]\n",
    "    probs = torch.softmax(outputs, dim=-1)\n",
    "    label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    label = label_map[probs.argmax().item()]\n",
    "    sentiment_probs.append((window_tokens, label))\n",
    "\n",
    "\n",
    "for tokens, label in sentiment_probs:\n",
    "    print(f\"Words: {tokens}, Sentiment: {label}, Score: {round(float(probs.max()), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba6cf5-870f-466e-9c59-904552ae3ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada028a-9f96-4ea5-b326-1a2619180ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Words: ['dined', 'here', 'twice', '.', 'german'], Sentiment: positive\n",
    "Words: ['viennese', 'cuisine', 'is', 'very', 'good'], Sentiment: positive\n",
    "Words: ['but', 'the', 'thai', 'meat', 'was'], Sentiment: negative\n",
    "Words: ['a', 'little', 'over', '##ex', '##posed'], Sentiment: negative\n",
    "Words: ['tira', '##mi', '##su', '-', 'probably'], Sentiment: positive\n",
    "Words: ['never', 'eaten', 'better', '!', 'desserts'], Sentiment: positive\n",
    "Words: ['were', 'all', 'without', 'exception', '.'], Sentiment: positive\n",
    "Words: ['service', 'is', 'pleasant'], Sentiment: positive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf7b1b9-41e5-4db6-ab53-e84195d718bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "76c6e751-6d65-4335-b54f-ce977506794e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 64>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment, \u001b[38;5;28mlist\u001b[39m(positive_words), positive_bigrams, \u001b[38;5;28mlist\u001b[39m(negative_words), negative_bigrams\n\u001b[0;32m     63\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe buffet breakfast was fantastic, but the room was cold.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 64\u001b[0m sentiment, positive_words, positive_bigrams, negative_words, negative_bigrams \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentiment)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(positive_bigrams)\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze_sentiment\u001b[39m(sentence):\n\u001b[1;32m----> 2\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m(sentence)\n\u001b[0;32m      3\u001b[0m     sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m      4\u001b[0m     positive_bigrams \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "def analyze_sentiment(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    sentiment = 0.0\n",
    "    positive_bigrams = []\n",
    "    negative_bigrams = []\n",
    "    positive_words = set()\n",
    "    negative_words = set()\n",
    "    prev_word = None\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'neg':\n",
    "            sentiment -= token.sentiment.polarity\n",
    "            negative_words.add(token.text)\n",
    "            prev_word = token.text\n",
    "        elif token.dep_ == 'amod' or token.dep_ == 'advmod':\n",
    "            if prev_word in negative_words:\n",
    "                negative_bigrams.append(prev_word + ' ' + token.text)\n",
    "            elif prev_word in positive_words:\n",
    "                positive_bigrams.append(prev_word + ' ' + token.text)\n",
    "            sentiment += token.sentiment.polarity\n",
    "            if token.sentiment.polarity < 0:\n",
    "                negative_words.add(token.text)\n",
    "            else:\n",
    "                positive_words.add(token.text)\n",
    "            prev_word = token.text\n",
    "        elif token.dep_ == 'compound':\n",
    "            if prev_word in negative_words:\n",
    "                negative_bigrams.append(prev_word + ' ' + token.text)\n",
    "            elif prev_word in positive_words:\n",
    "                positive_bigrams.append(prev_word + ' ' + token.text)\n",
    "            sentiment += token.sentiment.polarity\n",
    "            if token.sentiment.polarity < 0:\n",
    "                negative_words.add(token.text)\n",
    "            else:\n",
    "                positive_words.add(token.text)\n",
    "            prev_word = token.text\n",
    "        elif token.dep_ == 'nsubj':\n",
    "            if prev_word in negative_words:\n",
    "                negative_bigrams.append(prev_word + ' ' + token.text)\n",
    "            elif prev_word in positive_words:\n",
    "                positive_bigrams.append(prev_word + ' ' + token.text)\n",
    "            sentiment += token.sentiment.polarity\n",
    "            if token.sentiment.polarity < 0:\n",
    "                negative_words.add(token.text)\n",
    "            else:\n",
    "                positive_words.add(token.text)\n",
    "            prev_word = token.text\n",
    "        elif token.dep_ == 'dobj' or token.dep_ == 'attr':\n",
    "            if prev_word in negative_words:\n",
    "                negative_bigrams.append(prev_word + ' ' + token.text)\n",
    "            elif prev_word in positive_words:\n",
    "                positive_bigrams.append(prev_word + ' ' + token.text)\n",
    "            sentiment += token.sentiment.polarity\n",
    "            if token.sentiment.polarity < 0:\n",
    "                negative_words.add(token.text)\n",
    "            else:\n",
    "                positive_words.add(prev_word)\n",
    "            prev_word = token.text\n",
    "        else:\n",
    "            prev_word = None\n",
    "    return sentiment, list(positive_words), positive_bigrams, list(negative_words), negative_bigrams\n",
    "\n",
    "\n",
    "sentence = \"The buffet breakfast was fantastic, but the room was cold.\"\n",
    "sentiment, positive_words, positive_bigrams, negative_words, negative_bigrams = analyze_sentiment(sentence)\n",
    "print(sentiment)\n",
    "print(positive_bigrams)\n",
    "print(negative_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5e60300-4eda-4e5f-9795-19f7cf77a208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.5.0-cp310-cp310-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 12.2/12.2 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 48.9/48.9 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting thinc<8.2.0,>=8.1.0\n",
      "  Downloading thinc-8.1.9-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp310-cp310-win_amd64.whl (94 kB)\n",
      "     ---------------------------------------- 94.7/94.7 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (57.5.0)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp310-cp310-win_amd64.whl (18 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp310-cp310-win_amd64.whl (480 kB)\n",
      "     -------------------------------------- 480.9/480.9 kB 1.9 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (1.10.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     -------------------------------------- 181.6/181.6 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from spacy) (2.28.1)\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 56.8/56.8 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 smart-open-6.3.0 spacy-3.5.0 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.9 typer-0.7.0 wasabi-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8839020-3d35-4c59-b89c-9956af5fe113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7316f9-4318-4181-99fb-4786fd0a9874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afae73-c651-4854-b10b-0ba284f7e57b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7052d-f554-4fef-bd25-ee618f143f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdad74eb-414c-4fc5-91c6-c8ec7035fbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Q1 (April - June)</th>\n",
       "      <th>Q2 (July - September)</th>\n",
       "      <th>Q3 (October ‚Äì December)</th>\n",
       "      <th>Q4 (January - March)</th>\n",
       "      <th>FY (April - March)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FY2013</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FY2014</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FY2015</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FY2016</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FY2017</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FY2018</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FY2019</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FY2020</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FY2021</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0 Q1 (April - June) Q2 (July - September)  Q3 (October ‚Äì December)  \\\n",
       "0     FY2013                 -                     -                      4.5   \n",
       "1     FY2014               2.8                   3.4                      6.4   \n",
       "2     FY2015               2.9                   4.0                      8.4   \n",
       "3     FY2016               3.5                   3.9                      9.7   \n",
       "4     FY2017               3.3                   4.2                      9.0   \n",
       "5     FY2018               3.2                   3.9                      8.1   \n",
       "6     FY2019               3.2                   2.8                      6.0   \n",
       "7     FY2020               1.9                   1.5                      1.4   \n",
       "8     FY2021               0.5                   0.2                      0.2   \n",
       "\n",
       "   Q4 (January - March)  FY (April - March)  \n",
       "0                   3.1                 7.6  \n",
       "1                   2.3                14.8  \n",
       "2                   2.4                17.6  \n",
       "3                   2.9                20.0  \n",
       "4                   2.5                19.0  \n",
       "5                   2.6                17.8  \n",
       "6                   1.4                13.5  \n",
       "7                   1.0                 5.7  \n",
       "8                   0.1                 1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    " # attrs={'id': 'table'}\n",
    "tables = pd.read_html('https://www.sie.com/en/corporate/data.html')\n",
    "tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47a6a1bd-ed69-480f-a6ee-aa33bff763a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyodbc\n",
      "  Downloading pyodbc-4.0.35-cp310-cp310-win_amd64.whl (66 kB)\n",
      "     -------------------------------------- 66.0/66.0 kB 899.6 kB/s eta 0:00:00\n",
      "Installing collected packages: pyodbc\n",
      "Successfully installed pyodbc-4.0.35\n"
     ]
    }
   ],
   "source": [
    "!pip install pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5945ff8f-092b-491f-9722-27f01a6ee686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pyodbc\n",
    "import traceback\n",
    "\n",
    "\n",
    "# SQLALCHEMY_DATABASE_URI='postgresql://postgreadmin:P0stGr3Adm@model-builder-dev.postgres.database.azure.com:5432/postgres'\n",
    "# pyodbc.connect(SQLALCHEMY_DATABASE_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0c64a2c-8488-4d9e-8d82-05ba028ef6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\GIGABYTE\\AppData\\Local\\Temp\\ipykernel_27120\\1775844693.py\", line 13, in __init__\n",
      "    self._conn = pyodbc.connect(self.DRIVER + self.SERVER\\\n",
      "pyodbc.InterfaceError: ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DatabaseConnector.__exit__() missing 2 required positional arguments: 'exc_val' and 'exc_tb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInterfaceError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mDatabaseConnector.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn \u001b[38;5;241m=\u001b[39m \u001b[43mpyodbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDRIVER\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSERVER\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATABASE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUSERNAME\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPASSWORD\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mInterfaceError\u001b[0m: ('IM002', '[IM002] [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified (0) (SQLDriverConnect)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcursor\u001b[38;5;241m.\u001b[39mexecute(sql, params \u001b[38;5;129;01mor\u001b[39;00m ())\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mDatabaseConnector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m db:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(db\u001b[38;5;241m.\u001b[39mconnection)\n\u001b[0;32m     57\u001b[0m     db\u001b[38;5;241m.\u001b[39mupdate_pipeline_model_conf(pipeline_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m'\u001b[39m], created_pipe)\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mDatabaseConnector.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(traceback\u001b[38;5;241m.\u001b[39mprint_exception(e))\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__exit__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mcursor()\n",
      "\u001b[1;31mTypeError\u001b[0m: DatabaseConnector.__exit__() missing 2 required positional arguments: 'exc_val' and 'exc_tb'"
     ]
    }
   ],
   "source": [
    "class DatabaseConnector:\n",
    "    \"\"\"\n",
    "        A base DB connection class\n",
    "    \"\"\"\n",
    "    DRIVER   =  r'DRIVER=ODBC Driver 18 for SQL Server;'\n",
    "    SERVER   =  f'SERVER=model-builder-dev.postgres.database.azure.com;'\n",
    "    PORT     =  f'PORT={5432};'\n",
    "    DATABASE =  f'DATABASE={\"postgres\"};'\n",
    "    USERNAME =  f'UID=postgreadmin;'\n",
    "    PASSWORD =  f'PWD=P0stGr3Adm'\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self._conn = pyodbc.connect(self.DRIVER + self.SERVER\\\n",
    "                + self.DATABASE + self.USERNAME + self.PASSWORD)\n",
    "        except Exception as e:\n",
    "            print(traceback.print_exception(e))\n",
    "            self.__exit__(sys.exc_info())\n",
    "        self._cursor = self._conn.cursor()\n",
    "        \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.close()\n",
    "        \n",
    "    @property\n",
    "    def connection(self):\n",
    "        return self._conn\n",
    "    \n",
    "    @property\n",
    "    def cursor(self):\n",
    "        return self._cursor\n",
    "    \n",
    "    def commit(self):\n",
    "        self.connection.commit()\n",
    "        \n",
    "    def close(self, commit=True):\n",
    "        if commit:\n",
    "            self.commit()\n",
    "        self.connection.close()\n",
    "        \n",
    "    def execute(self, sql, params=None):\n",
    "        self.cursor.execute(sql, params or ())\n",
    "        \n",
    "    def fetchall(self):\n",
    "        return self.cursor.fetchall()\n",
    "    \n",
    "    def fetchone(self):\n",
    "        return self.cursor.fetchone()\n",
    "    \n",
    "    def query(self, sql, params=None):\n",
    "        self.cursor.execute(sql, params or ())\n",
    "        return self.fetchall()\n",
    "\n",
    "with DatabaseConnector() as db:\n",
    "    print(db.connection)\n",
    "    db.update_pipeline_model_conf(pipeline_data['model_config'], created_pipe)\n",
    "    db.update_model_pipeline(created_pipe, created_model)\n",
    "    db.update_features(fea_list, DATASET_ID, created_pipe)\n",
    "    db.update_modelobject(MODEL_OBJECT_ID, created_model)\n",
    "    print(db.connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a7713-c9b8-414a-a281-815ff235a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "traceback.print_exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61152792-b4fa-4486-9f8e-0a3f488112c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8acb3ffe-db92-43b1-b00b-a78d00cec10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "     ------------------------------------ 112.2/112.2 kB 935.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from html5lib) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\gigabyte\\anaconda3\\envs\\tf_gpu\\lib\\site-packages (from html5lib) (0.5.1)\n",
      "Installing collected packages: html5lib\n",
      "Successfully installed html5lib-1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
